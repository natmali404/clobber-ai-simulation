{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1905014",
   "metadata": {},
   "source": [
    "# **Minimax algorithm with alpha-beta pruning on a decision tree**\n",
    "## A Clobber AI simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc41005",
   "metadata": {},
   "source": [
    "### 1. **Intro**\n",
    "\n",
    "The goal of this project is to simulate a game-playing AI for the game Clobber using the Minimax algorithm, enhanced with alpha-beta pruning. \n",
    "\n",
    "Clobber is a two-player turn-based game played on a rectangular grid. Each cell initially contains either a white or black piece, corresponding to one of the two players. On their turn, a player moves one of their own pieces onto an adjacent opponent's piece, effectively capturing it. The player who cannot make a move on their turn loses. \n",
    "\n",
    "This report outlines the theoretical basis of the Minimax algorithm, defines the problem formally, describes the used heuristics and presents the implementation details of the Clobber.\n",
    "\n",
    "#### **Used Python libraries**\n",
    "- time - for performance measurement\n",
    "- cProfile - for performance analysis\n",
    "- dataclasses, typing - for type hints and overall better experience\n",
    "- argparse - for parsing arguments and running the simulation\n",
    "- random - for algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ab8e8",
   "metadata": {},
   "source": [
    "### 2. **Method Description**\n",
    "\n",
    "#### **Minimax algorithm**\n",
    "\n",
    "Minimax is a recursive algorithm used for decision-making in two-player games. It assumes both players play optimally: one player (Max) tries to maximize their score, while the opponent (Min) tries to minimize it. The algorithm constructs a game tree of all possible future moves, evaluates terminal nodes using a heuristic function, and backtracks to determine the optimal current move.\n",
    "\n",
    "#### **Alpha-Beta Pruning**\n",
    "\n",
    "Alpha-beta pruning is an optimization technique for Minimax. It eliminates branches in the game tree that cannot possibly affect the final decision, reducing the number of nodes evaluated. Two values are maintained during traversal:\n",
    "\n",
    "- Alpha: the best value found so far for the Max player.\n",
    "- Beta: the best value found so far for the Min player.\n",
    "\n",
    "If at any point Beta â‰¤ Alpha, further exploration of that branch is stopped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551fc0ec",
   "metadata": {},
   "source": [
    "### 3. **Problem Definition and My Solution**\n",
    "\n",
    "#### **Game state**\n",
    "\n",
    "A game state in Clobber is represented as a 2D grid (matrix), where each cell contains either:\n",
    "\n",
    "- 'W' for a white piece,\n",
    "- 'B' for a black piece,\n",
    "- '_' for an empty cell (after a piece has moved).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083e68d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a relevant fragment of my gamestate class\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class GameState:\n",
    "    n: int\n",
    "    m: int\n",
    "    board: List[List[str]]\n",
    "    \n",
    "\n",
    "    # board generation\n",
    "    def generate_starting_board(self, n: int, m: int) -> List[List[str]]:\n",
    "        new_board = []\n",
    "        is_black = True\n",
    "        for j in range(m):\n",
    "            new_row = []\n",
    "            if j > 0: #make sure its checkered\n",
    "                is_black = new_board[j-1][0] == \"W\"\n",
    "            for i in range(n):\n",
    "                new_row.append(\"B\" if is_black else \"W\")\n",
    "                is_black = not is_black\n",
    "            new_board.append(new_row)\n",
    "        return new_board\n",
    "    \n",
    "    \n",
    "    # calculating possible moves for a given player\n",
    "    def get_possible_moves(self, player_color: str) -> List[\"Move\"]:\n",
    "        enemy_color = \"B\" if player_color == \"W\" else \"W\"\n",
    "        possible_moves = []\n",
    "        \n",
    "        for j in range(self.m):\n",
    "            for i in range(self.n):\n",
    "                if self.board[j][i] == player_color:\n",
    "                    #j-1, i; j, i+1; j+1, i; j, i-1\n",
    "                    for direction_j, direction_i in [(-1, 0), (1, 0), (0, -1), (0,1)]:\n",
    "                        new_j, new_i = j + direction_j, i + direction_i\n",
    "                        if 0 <= new_j < self.m and 0 <= new_i < self.n and self.board[new_j][new_i] == enemy_color:\n",
    "                                possible_moves.append(Move(i, j, new_i, new_j))\n",
    "        \n",
    "        return possible_moves\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f22d4",
   "metadata": {},
   "source": [
    "#### **Move**\n",
    "\n",
    "A move consists of selecting a player's piece and moving it to an adjacent (orthogonal) cell containing an opponent's piece. The opponent's piece is removed, and the player piece occupies the new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87758c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Move:\n",
    "    from_x: int\n",
    "    from_y: int\n",
    "    to_x: int\n",
    "    to_y: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f62c2",
   "metadata": {},
   "source": [
    "#### **Goal function**\n",
    "\n",
    "The objective of the AI is to make moves that increase the chance of winning. The heuristic evaluation function estimates how favorable a given game state is for a player. It is based on factors such as:\n",
    "\n",
    "- Number of available moves (mobility),\n",
    "- Number of remaining pieces,\n",
    "- Central control (preference for center tiles)\n",
    "\n",
    "Below are implemented heuristics. They are calculated using weights. Weights change depending on the game progress.\n",
    "\n",
    "**Implemented strategy:**\n",
    "- EARLY GAME: mobility prioritization (available moves)\n",
    "- MID GAME: middle control prioritization\n",
    "- END GAME: piece count prioritization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d586a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval methods\n",
    "def evaluate(gamestate: GameState, player_color: str, rounds: int):\n",
    "    h1 = mobility_heuristic(gamestate, player_color)\n",
    "    h2 = piece_advantage_heuristic(gamestate, player_color)\n",
    "    h3 = central_control_heuristic(gamestate, player_color)\n",
    "    \n",
    "    w1, w2, w3 = dynamic_weights(rounds)\n",
    "\n",
    "    return w1 * h1 + w2 * h2 + w3 * h3\n",
    "\n",
    "\n",
    "def dynamic_weights(rounds):\n",
    "    base_weights = (1, 1, 1)\n",
    "    if rounds < 10:\n",
    "        return (base_weights[0] + 2, base_weights[1], base_weights[2])\n",
    "    elif rounds < 20:\n",
    "        return (base_weights[0], base_weights[1], base_weights[2] + 2)\n",
    "    else:\n",
    "        return (base_weights[0], base_weights[1] + 2, base_weights[2])\n",
    "    \n",
    "\n",
    "#heuristics implementation\n",
    "def mobility_heuristic(state: GameState, player_color: str):\n",
    "    return len(state.get_possible_moves(player_color))\n",
    "\n",
    "def piece_advantage_heuristic(state: GameState, player_color: str):\n",
    "    my_pieces = state.count_pieces(player_color)\n",
    "    opponent_pieces = state.count_pieces(\"B\" if player_color == \"W\" else \"W\")\n",
    "    return my_pieces - opponent_pieces\n",
    "\n",
    "def central_control_heuristic(state: GameState, player_color: str):\n",
    "    height = len(state.board)\n",
    "    width = len(state.board[0])\n",
    "    center_row, center_col = height // 2, width // 2\n",
    "    score = 0\n",
    "    for r in range(height):\n",
    "        for c in range(width):\n",
    "            if state.board[r][c] == player_color:\n",
    "                distance = abs(center_row - r) + abs(center_col - c)\n",
    "                score += (height + width) - distance\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9d254",
   "metadata": {},
   "source": [
    "#### **Decision Tree**\n",
    "\n",
    "The decision tree is built using a depth-limited search. Each node represents a game state. It contains a move that led to the game state, its parent, its children (further possible gamestates) and a score, calculated using the heuristics.\n",
    "\n",
    "The tree alternates between Max and Min levels. At a certain depth, the leaf nodes are evaluated heuristically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae4ce83",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# node implementation\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;129;43m@dataclass\u001b[39;49m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mNode\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgamestate\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mGameState\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNode\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mNode\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mNode\u001b[39;00m:\n\u001b[32m      5\u001b[39m     gamestate: GameState\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     parent: \u001b[43mOptional\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mNode\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m     move: Move\n\u001b[32m      8\u001b[39m     children: List[\u001b[33m\"\u001b[39m\u001b[33mNode\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'Optional' is not defined"
     ]
    }
   ],
   "source": [
    "# node implementation\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    gamestate: GameState\n",
    "    parent: Optional[\"Node\"]\n",
    "    move: Move\n",
    "    children: List[\"Node\"]\n",
    "    score: int\n",
    "    \n",
    "    def __init__(self, gamestate, parent=None, move=None):\n",
    "        self.gamestate = gamestate\n",
    "        self.parent = parent\n",
    "        self.move = move \n",
    "        self.children = []\n",
    "        self.score = 0\n",
    "\n",
    "    def add_child(self, child_node):\n",
    "        self.children.append(child_node)\n",
    "        \n",
    "\n",
    "@dataclass\n",
    "class DecisionTree:\n",
    "    root: Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f56793",
   "metadata": {},
   "source": [
    "#### Minimax (traditional) implementation within the DecisionTree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafd5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(self, node: Node, depth: int, player_color: str, player_goal: str, rounds: int):\n",
    "\n",
    "        #search tree from the node (root)\n",
    "        #if childless node (leaf) or end of depth, we return for the player whos making the move\n",
    "        possible_moves = node.gamestate.get_possible_moves(player_color)\n",
    "        if depth == 0 or not possible_moves:\n",
    "            node.score = evaluate(node.gamestate, player_color, rounds)\n",
    "            return node.score\n",
    "            \n",
    "        #else for each child node we use minimax recursively\n",
    "        #assign the max/min value from the child nodes to the current node (max/min depends on what the player is)\n",
    "        \n",
    "        #prepare dummy enemy\n",
    "        opponent_color = \"W\" if player_color == \"B\" else \"B\"\n",
    "        opponent_goal = \"MIN\" if player_goal == \"MAX\" else \"MAX\"\n",
    "        \n",
    "        if player_goal == \"MAX\":\n",
    "            max_evaluation = float(\"-inf\")\n",
    "            best_child = None\n",
    "            \n",
    "            for move in possible_moves:\n",
    "                new_state = node.gamestate.copy()\n",
    "                new_state.make_move(move)\n",
    "                child = Node(gamestate=new_state, parent=node, move=move)\n",
    "                if node == self.root:\n",
    "                    node.add_child(child)\n",
    "                evaluation = self.minimax(child, depth-1, opponent_color, opponent_goal, rounds)\n",
    "                if evaluation > max_evaluation:\n",
    "                    max_evaluation = evaluation\n",
    "                    best_child = child\n",
    "            node.score = max_evaluation\n",
    "            if node == self.root:\n",
    "                return best_child.move\n",
    "            return max_evaluation\n",
    "        \n",
    "        else: #player_goal == \"MIN\"\n",
    "            min_evaluation = float(\"inf\")\n",
    "            best_child = None\n",
    "            for move in possible_moves:\n",
    "                new_state = node.gamestate.copy()\n",
    "                new_state.make_move(move)\n",
    "                child = Node(new_state, parent=node, move=move)\n",
    "                node.add_child(child)\n",
    "                evaluation = self.minimax(child, depth-1, opponent_color, opponent_goal, rounds)\n",
    "                if evaluation < min_evaluation:\n",
    "                    min_evaluation = evaluation\n",
    "                    best_child = child\n",
    "            node.score = min_evaluation\n",
    "            if node == self.root:\n",
    "                return best_child.move\n",
    "            return min_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01766096",
   "metadata": {},
   "source": [
    "#### Minimax with alpha-beta pruning implementation within the DecisionTree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c68fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta(self, node: Node, depth: int, player_color: str, player_goal: str, rounds: int, alpha: float = float(\"-inf\"), beta: float = float(\"inf\")):\n",
    "\n",
    "        possible_moves = node.gamestate.get_possible_moves(player_color)\n",
    "        if depth == 0 or not possible_moves:\n",
    "            node.score = evaluate(node.gamestate, player_color, rounds)\n",
    "            return node.score\n",
    "\n",
    "        opponent_color = \"W\" if player_color == \"B\" else \"B\"\n",
    "        opponent_goal = \"MIN\" if player_goal == \"MAX\" else \"MAX\"\n",
    "\n",
    "        if player_goal == \"MAX\":\n",
    "            max_evaluation = float(\"-inf\")\n",
    "            best_child = None\n",
    "\n",
    "            for move in possible_moves:\n",
    "                new_state = node.gamestate.copy()\n",
    "                new_state.make_move(move)\n",
    "                child = Node(gamestate=new_state, parent=node, move=move)\n",
    "                if node == self.root:\n",
    "                    node.add_child(child)\n",
    "                \n",
    "                evaluation = self.alphabeta(child, depth - 1, opponent_color, opponent_goal, rounds, alpha, beta)\n",
    "                if evaluation > max_evaluation:\n",
    "                    max_evaluation = evaluation\n",
    "                    best_child = child\n",
    "\n",
    "                alpha = max(alpha, evaluation)\n",
    "                if beta <= alpha:\n",
    "                    break  #pruning\n",
    "\n",
    "            node.score = max_evaluation\n",
    "            if node == self.root:\n",
    "                return best_child.move\n",
    "            return max_evaluation\n",
    "\n",
    "        else:  #player_goal == \"MIN\"\n",
    "            min_evaluation = float(\"inf\")\n",
    "            best_child = None\n",
    "\n",
    "            for move in possible_moves:\n",
    "                new_state = node.gamestate.copy()\n",
    "                new_state.make_move(move)\n",
    "                child = Node(gamestate=new_state, parent=node, move=move)\n",
    "                node.add_child(child)\n",
    "\n",
    "                evaluation = self.alphabeta(child, depth - 1, opponent_color, opponent_goal, rounds, alpha, beta)\n",
    "                if evaluation < min_evaluation:\n",
    "                    min_evaluation = evaluation\n",
    "                    best_child = child\n",
    "\n",
    "                beta = min(beta, evaluation)\n",
    "                if beta <= alpha:\n",
    "                    break  #pruning\n",
    "\n",
    "            node.score = min_evaluation\n",
    "            if node == self.root:\n",
    "                return best_child.move\n",
    "            return min_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae9071",
   "metadata": {},
   "source": [
    "#### **Game progress**\n",
    "\n",
    "The game itself is played within a simple loop in main(). While the gameover condition wasn't met, the players keep making moves. The player who made the last viable move is the winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = parse_args()\n",
    "    \n",
    "    #gameplay preparation\n",
    "    player_classes = {\"minimax\": MinimaxPlayer, \"random\": RandomPlayer, \"greedy\": GreedyPlayer,}\n",
    "    player1_class = player_classes.get(args.player1)\n",
    "    player2_class = player_classes.get(args.player2)\n",
    "\n",
    "    player1 = player1_class(color=\"B\", goal=\"MAX\", depth=args.depth, pruning=args.pruning) if player1_class == MinimaxPlayer else player1_class(color=\"B\", goal=\"MAX\")\n",
    "    player2 = player2_class(color=\"W\", goal=\"MIN\", depth=args.depth, pruning=args.pruning) if player2_class == MinimaxPlayer else player2_class(color=\"W\", goal=\"MIN\")\n",
    "\n",
    "    gamestate = GameState(n=args.n, m=args.m)\n",
    "    rounds = 1\n",
    "    current_player = player1\n",
    "    gameover = False\n",
    "\n",
    "    #gameplay\n",
    "    while not gameover:\n",
    "        print_round_info(rounds, current_player)\n",
    "        \n",
    "        possible_moves = gamestate.get_possible_moves(current_player.color)\n",
    "        \n",
    "        if possible_moves:\n",
    "            move = current_player.choose_move(gamestate, rounds)\n",
    "            gamestate.make_move(move)\n",
    "            current_player = player2 if current_player == player1 else player1\n",
    "            rounds += 1\n",
    "            gamestate.print_board()\n",
    "        else:\n",
    "            print(\"No moves available left!\")\n",
    "            gameover = True\n",
    "        \n",
    "    winning_player = \"Player1\" if current_player == player2 else \"Player2\"\n",
    "    print(\"Winner: \", winning_player)\n",
    "    print(\"Round count: \", rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e48cf",
   "metadata": {},
   "source": [
    "#### **Players**\n",
    "\n",
    "There are three different players defined in the game:\n",
    "\n",
    "- MinimaxPlayer - playes \"by the rules\", using decision tree and minimax algorithm\n",
    "- RandomPlayer - always chooses the random possible move\n",
    "- GreedyPlayer - analyses all currently possible moves and makes the best one without looking forward into the future moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MinimaxPlayer(Player):\n",
    "    depth: int\n",
    "    pruning: bool = False\n",
    "    \n",
    "    def choose_move(self, gamestate: GameState, rounds: int):\n",
    "        tree = DecisionTree(Node(gamestate.copy()))\n",
    "        if self.pruning:\n",
    "            best_move = tree.alphabeta(tree.root, self.depth, self.color, self.goal, rounds)\n",
    "        else:\n",
    "            best_move = tree.minimax(tree.root, self.depth, self.color, self.goal, rounds)\n",
    "        \n",
    "        return best_move\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class RandomPlayer(Player):\n",
    "    def choose_move(self, gamestate: GameState, rounds: int):\n",
    "        possible_moves = gamestate.get_possible_moves(self.color)\n",
    "        if not possible_moves:\n",
    "            return None\n",
    "        return random.choice(possible_moves)\n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class GreedyPlayer(Player):\n",
    "    def choose_move(self, gamestate: GameState, rounds: int):\n",
    "        possible_moves = gamestate.get_possible_moves(self.color)\n",
    "        if not possible_moves:\n",
    "            return None\n",
    "        \n",
    "        best_move = None\n",
    "        best_score = float(\"-inf\") if self.goal == \"MAX\" else float(\"inf\")\n",
    "        \n",
    "        for move in possible_moves:\n",
    "            new_state = gamestate.copy()\n",
    "            new_state.make_move(move)\n",
    "            score = evaluate(new_state, self.color, rounds)\n",
    "            \n",
    "            if self.goal == \"MAX\" and score > best_score:\n",
    "                best_score = score\n",
    "                best_move = move\n",
    "            elif self.goal == \"MIN\" and score < best_score:\n",
    "                best_score = score\n",
    "                best_move = move\n",
    "        \n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c44490",
   "metadata": {},
   "source": [
    "### 4. **Results**\n",
    "\n",
    "\n",
    "\n",
    "### 5. Areas for improvement and further development\n",
    "\n",
    "### 6. Sources\n",
    "    - results\n",
    "    - areas for improvement/further development"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
